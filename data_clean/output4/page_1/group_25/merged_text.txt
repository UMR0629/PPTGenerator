PREDATOR achieved good results in the evaluation, yet
there remains room for improvement. In this section, we
discuss some limitations and possible future work.
Performance of Static Analysis Tools. The effectiveness
of PREDATOR highly depends on the performance of the
static analysis tools. For reproducing known vulnerabilities,
these tools need to identify potential execution paths as
accurately as possible. This assists in analyzing the paths
that are likely to lead to the target locations and calculating
the block distances. The current tools are not perfect in this
regard, especially when the target application is complex
or contains new language syntax that the tools cannot
handle [6, 10]. Additionally, some PHP frameworks, such
as Laravel, may dynamically register HTTP URLs and their
handling functions to define URL entries, causing PREDATOR
to potentially miss these entry URLs.
The capability of PREDATOR to detect new vulnerabilities
relies heavily on the results of static analysis. PREDATOR
can dynamically validate the potential targets to reduce the
false positives, but the false negatives are still a problem.
Unfortunately, many vulnerable locations are not identified
by the current static analysis tools [9]. We observed that
TChecker failed to analyze some applications, possibly due
to the complexity of the applications or its inability to
model new PHP syntax. This is a common problem for
static analysis tools, which we leave for future work.
Directed Web Fuzzing. As a directed fuzzer, PREDATOR
guides the fuzzing process towards the target locations. It
requires preparatory work to identify the potential targets.
This is a language-specific task, thus we need to use a
specific static analysis tool for one language. As PHP is the
most popular server-side language for web development [5],
we chose PHP as the target language in our prototype. The
distance feedback mechanism is currently implemented in the
PHP interpreter, which could be extended to other interpreted
languages.
One distinguishing aspect of web fuzzing, compared to
other fuzzing domains, is the necessity to analyze the URLs
associated with the application’s different functionalities
and the structured parameters included in these URLs.
PREDATOR extracts URLs and builds input corpus from
source code through lightweight static analysis, differing
from the commonly employed crawling method. However, the
static analysis method cannot handle dynamically generated
URLs. One possible approach is to integrate static analysis
with a crawler. The results from the crawler can facilitate
the exploitation of easily accessible vulnerabilities, while
static analysis provides more detailed insights into exploring
deeper execution paths.
Bug Oracles. PREDATOR leverages Witcher’s customized
bug oracles to detect SQL injection and command injection
vulnerabilities. A reflected XSS detector is implemented to
demonstrate its potential to detect more types of vulnera-
bilities. However, there are limitations of the current bug
oracles. For example, the current SQL injection oracle only
supports MySQL and PostgreSQL, limiting its applicability
across diverse database environments. The XSS detector
introduces false positives. Additionally, PREDATOR currently
does not support a broader spectrum of vulnerabilities,
such as server-side request forgery (SSRF). This issue
could be addressed by extending the current bug oracles
or implementing PREDATOR upon other fuzzers capable of
detecting more types of vulnerabilities.